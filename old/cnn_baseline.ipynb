{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from models.cnn_models import cnn_baseline, cnn_multihead, cnn_cnnhpss\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from data_utility.file_utility import FileUtility\n",
    "from data_utility.labeling_utility import LabelingData\n",
    "import itertools\n",
    "from data_utility.feedgenerator import train_batch_generator_408, validation_batch_generator_408\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_baseline(epochs=10, setting_name='basemodel', gpu='1', train_batch_size=64,\n",
    "                 test_batch_size=100, patience=10, features_to_use=['onehot', 'sequence_profile'], convs=[3, 5, 7], dense_size=200,use_CRF=False,filter_size=256):\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "\n",
    "    # read files\n",
    "    train_file = '../DeepSeq2Sec/data/s8_all_features/train.txt'\n",
    "    test_file = '../DeepSeq2Sec/data/s8_all_features/test.txt'\n",
    "    LD = LabelingData(train_file, test_file)\n",
    "    train_lengths = [int(j) for j in FileUtility.load_list('/'.join(train_file.split('/')[0:-1]) + '/train_length.txt')]\n",
    "    test_lengths = [int(i) for i in FileUtility.load_list('/'.join(test_file.split('/')[0:-1]) + '/test_length.txt')]\n",
    "\n",
    "    # model\n",
    "    model, params = cnn_cnnhpss(LD.n_classes, features_to_use=features_to_use, convs=convs,\n",
    "                             dense_size=dense_size, use_CRF=use_CRF, filter_size=filter_size)\n",
    "\n",
    "    # output directory\n",
    "    FileUtility.ensure_dir('results_cnn/' + setting_name + params + '/')\n",
    "\n",
    "    # save model\n",
    "    with open('results_cnn/' + setting_name + params + '/' + 'config.txt', 'w') as fh:\n",
    "        model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "\n",
    "    # check points\n",
    "    filepath = 'results_cnn/' + setting_name + params + \"/weights-improvement-{epoch:02d}-{weighted_acc:.3f}-{val_weighted_acc:.3f}.hdf5\"\n",
    "    #checkpoint = ModelCheckpoint(filepath, monitor='val_weighted_acc', verbose=1, save_best_only=True, mode='max',                                 period=1)\n",
    "    earlystopping = EarlyStopping(monitor='val_weighted_acc', min_delta=0, patience=patience, verbose=0, mode='max', baseline=None)\n",
    "    callbacks_list = [earlystopping]#checkpoint]#, \n",
    "\n",
    "    # calculate the sizes\n",
    "    steps_per_epoch = len(train_lengths) / train_batch_size if len(train_lengths) % train_batch_size == 0 else int(\n",
    "        len(train_lengths) / train_batch_size) + 1\n",
    "    validation_steps = int(len(test_lengths) / test_batch_size) if len(test_lengths) % test_batch_size == 0 else int(\n",
    "        len(test_lengths) / test_batch_size) + 1\n",
    "\n",
    "    # feed model\n",
    "    h = model.fit_generator(train_batch_generator_408(train_batch_size), steps_per_epoch=steps_per_epoch,\n",
    "                            validation_data=validation_batch_generator_408(test_batch_size),\n",
    "                            validation_steps=validation_steps,\n",
    "                            shuffle=False, epochs=epochs, verbose=1, callbacks=callbacks_list)\n",
    "\n",
    "    # save the history\n",
    "    FileUtility.save_obj('results_cnn/' + setting_name + params + '/history', h.history)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling utility object created..\n",
      "Training y encoded shape is  (5534, 700)\n",
      "Maximum sequence length is 700\n",
      "Tensor(\"crf1/cond/Merge:0\", shape=(?, ?, 9), dtype=float32)\n",
      "(None, None, 9)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, 408)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "onehot (Lambda)                 (None, None, 21)     0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequenceprofile (Lambda)        (None, None, 21)     0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, None, 42)     0           onehot[0][0]                     \n",
      "                                                                 sequenceprofile[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batchnorm_input (BatchNormaliza (None, None, 42)     168         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv1D)                  (None, None, 80)     23600       batchnorm_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv1D)                  (None, None, 80)     30320       batchnorm_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv1D)                  (None, None, 80)     37040       batchnorm_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_conv1 (BatchNormaliz (None, None, 80)     320         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_conv2 (BatchNormaliz (None, None, 80)     320         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_conv3 (BatchNormaliz (None, None, 80)     320         conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, None, 240)    0           batch_norm_conv1[0][0]           \n",
      "                                                                 batch_norm_conv2[0][0]           \n",
      "                                                                 batch_norm_conv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_2nd_1 (Conv1D)             (None, None, 80)     134480      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_2nd_2 (Conv1D)             (None, None, 80)     172880      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_2nd_3 (Conv1D)             (None, None, 80)     211280      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_conv_2nd_1 (BatchNor (None, None, 80)     320         conv_2nd_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_conv_2nd_2 (BatchNor (None, None, 80)     320         conv_2nd_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_conv_2nd_3 (BatchNor (None, None, 80)     320         conv_2nd_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, None, 240)    0           batch_norm_conv_2nd_1[0][0]      \n",
      "                                                                 batch_norm_conv_2nd_2[0][0]      \n",
      "                                                                 batch_norm_conv_2nd_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None, 240)    0           concatenate_6[0][0]              \n",
      "                                                                 concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_3nd_1 (Conv1D)             (None, None, 80)     134480      lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_3nd_2 (Conv1D)             (None, None, 80)     172880      lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_3nd_3 (Conv1D)             (None, None, 80)     211280      lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_conv_3nd_1 (BatchNor (None, None, 80)     320         conv_3nd_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_conv_3nd_2 (BatchNor (None, None, 80)     320         conv_3nd_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_conv_3nd_3 (BatchNor (None, None, 80)     320         conv_3nd_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, None, 240)    0           batch_norm_conv_3nd_1[0][0]      \n",
      "                                                                 batch_norm_conv_3nd_2[0][0]      \n",
      "                                                                 batch_norm_conv_3nd_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, None, 240)    0           lambda_3[0][0]                   \n",
      "                                                                 concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 240)    0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, None, 100)    24100       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 9)      909         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "crf1 (ChainCRF)                 (None, None, 9)      99          time_distributed_2[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 1,156,396\n",
      "Trainable params: 1,154,872\n",
      "Non-trainable params: 1,524\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/1000\n",
      "111/111 [==============================] - 54s 486ms/step - loss: 201.3839 - weighted_acc: 0.6316 - val_loss: 299.7006 - val_weighted_acc: 0.6454\n",
      "Epoch 2/1000\n",
      "111/111 [==============================] - 33s 301ms/step - loss: 163.0631 - weighted_acc: 0.6901 - val_loss: 279.3252 - val_weighted_acc: 0.6587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000\n",
      "111/111 [==============================] - 32s 292ms/step - loss: 147.2050 - weighted_acc: 0.7023 - val_loss: 264.6507 - val_weighted_acc: 0.6620\n",
      "Epoch 4/1000\n",
      "111/111 [==============================] - 33s 294ms/step - loss: 135.8951 - weighted_acc: 0.7111 - val_loss: 254.4420 - val_weighted_acc: 0.6607\n",
      "Epoch 5/1000\n",
      "111/111 [==============================] - 33s 301ms/step - loss: 126.9463 - weighted_acc: 0.7172 - val_loss: 246.3191 - val_weighted_acc: 0.6590\n",
      "Epoch 6/1000\n",
      "111/111 [==============================] - 34s 305ms/step - loss: 119.5060 - weighted_acc: 0.7225 - val_loss: 240.6140 - val_weighted_acc: 0.6586\n",
      "Epoch 7/1000\n",
      "111/111 [==============================] - 34s 307ms/step - loss: 113.8536 - weighted_acc: 0.7250 - val_loss: 236.0492 - val_weighted_acc: 0.6552\n",
      "Epoch 8/1000\n",
      "111/111 [==============================] - 34s 304ms/step - loss: 108.2496 - weighted_acc: 0.7303 - val_loss: 235.0536 - val_weighted_acc: 0.6409\n",
      "Epoch 9/1000\n",
      "111/111 [==============================] - 33s 299ms/step - loss: 103.5914 - weighted_acc: 0.7333 - val_loss: 235.3635 - val_weighted_acc: 0.6207\n",
      "Epoch 10/1000\n",
      "111/111 [==============================] - 34s 304ms/step - loss: 99.0949 - weighted_acc: 0.7323 - val_loss: 231.7329 - val_weighted_acc: 0.6315\n",
      "Epoch 11/1000\n",
      "111/111 [==============================] - 33s 300ms/step - loss: 93.5226 - weighted_acc: 0.7414 - val_loss: 229.6795 - val_weighted_acc: 0.6378\n",
      "Epoch 12/1000\n",
      "111/111 [==============================] - 33s 300ms/step - loss: 89.1718 - weighted_acc: 0.7472 - val_loss: 228.6953 - val_weighted_acc: 0.6356\n",
      "Epoch 13/1000\n",
      "111/111 [==============================] - 34s 305ms/step - loss: 85.3241 - weighted_acc: 0.7515 - val_loss: 226.0623 - val_weighted_acc: 0.6369\n",
      "Epoch 14/1000\n",
      "111/111 [==============================] - 33s 301ms/step - loss: 81.9454 - weighted_acc: 0.7563 - val_loss: 225.8495 - val_weighted_acc: 0.6348\n",
      "Epoch 15/1000\n",
      "111/111 [==============================] - 34s 304ms/step - loss: 78.7540 - weighted_acc: 0.7596 - val_loss: 225.5799 - val_weighted_acc: 0.6249\n",
      "Epoch 16/1000\n",
      "111/111 [==============================] - 34s 304ms/step - loss: 76.1083 - weighted_acc: 0.7622 - val_loss: 224.7477 - val_weighted_acc: 0.6312\n",
      "Epoch 17/1000\n",
      "111/111 [==============================] - 33s 300ms/step - loss: 74.1577 - weighted_acc: 0.7627 - val_loss: 223.4031 - val_weighted_acc: 0.6348\n",
      "Epoch 18/1000\n",
      "111/111 [==============================] - 33s 298ms/step - loss: 72.2508 - weighted_acc: 0.7629 - val_loss: 224.2226 - val_weighted_acc: 0.6274\n",
      "Epoch 19/1000\n",
      "111/111 [==============================] - 33s 301ms/step - loss: 70.0880 - weighted_acc: 0.7634 - val_loss: 222.9556 - val_weighted_acc: 0.6297\n",
      "Epoch 20/1000\n",
      "111/111 [==============================] - 33s 298ms/step - loss: 67.2698 - weighted_acc: 0.7700 - val_loss: 222.8685 - val_weighted_acc: 0.6236\n",
      "Epoch 21/1000\n",
      "111/111 [==============================] - 33s 299ms/step - loss: 64.3741 - weighted_acc: 0.7794 - val_loss: 219.7355 - val_weighted_acc: 0.6288\n",
      "Epoch 22/1000\n",
      "111/111 [==============================] - 33s 300ms/step - loss: 61.8549 - weighted_acc: 0.7840 - val_loss: 218.6713 - val_weighted_acc: 0.6292\n",
      "Epoch 23/1000\n",
      "111/111 [==============================] - 34s 303ms/step - loss: 59.3854 - weighted_acc: 0.7891 - val_loss: 218.1892 - val_weighted_acc: 0.6289\n",
      "Epoch 24/1000\n",
      "111/111 [==============================] - 34s 302ms/step - loss: 57.6800 - weighted_acc: 0.7926 - val_loss: 218.8682 - val_weighted_acc: 0.6200\n",
      "Epoch 25/1000\n",
      "111/111 [==============================] - 33s 299ms/step - loss: 55.8171 - weighted_acc: 0.7946 - val_loss: 218.3147 - val_weighted_acc: 0.6246\n",
      "Epoch 26/1000\n",
      "111/111 [==============================] - 34s 307ms/step - loss: 54.6693 - weighted_acc: 0.7964 - val_loss: 217.9798 - val_weighted_acc: 0.6289\n",
      "Epoch 27/1000\n",
      "111/111 [==============================] - 34s 304ms/step - loss: 53.3284 - weighted_acc: 0.7975 - val_loss: 218.4112 - val_weighted_acc: 0.6288\n",
      "Epoch 28/1000\n",
      "111/111 [==============================] - 34s 307ms/step - loss: 52.2952 - weighted_acc: 0.7978 - val_loss: 219.6923 - val_weighted_acc: 0.6248\n",
      "Epoch 29/1000\n",
      "111/111 [==============================] - 33s 302ms/step - loss: 50.9083 - weighted_acc: 0.7985 - val_loss: 218.7172 - val_weighted_acc: 0.6300\n",
      "Epoch 30/1000\n",
      "111/111 [==============================] - 34s 303ms/step - loss: 49.0095 - weighted_acc: 0.8019 - val_loss: 220.5761 - val_weighted_acc: 0.6227\n",
      "Epoch 31/1000\n",
      "111/111 [==============================] - 34s 302ms/step - loss: 47.5153 - weighted_acc: 0.8048 - val_loss: 220.4491 - val_weighted_acc: 0.6234\n",
      "Epoch 32/1000\n",
      "111/111 [==============================] - 33s 296ms/step - loss: 46.6126 - weighted_acc: 0.8039 - val_loss: 219.6898 - val_weighted_acc: 0.6254\n",
      "Epoch 33/1000\n",
      "111/111 [==============================] - 34s 303ms/step - loss: 45.4865 - weighted_acc: 0.8053 - val_loss: 217.6567 - val_weighted_acc: 0.6307\n",
      "Epoch 34/1000\n",
      "111/111 [==============================] - 34s 303ms/step - loss: 44.4521 - weighted_acc: 0.8068 - val_loss: 219.3124 - val_weighted_acc: 0.6263\n",
      "Epoch 35/1000\n",
      "111/111 [==============================] - 34s 303ms/step - loss: 42.8371 - weighted_acc: 0.8109 - val_loss: 218.6853 - val_weighted_acc: 0.6293\n",
      "Epoch 36/1000\n",
      "111/111 [==============================] - 34s 307ms/step - loss: 41.4179 - weighted_acc: 0.8161 - val_loss: 219.8608 - val_weighted_acc: 0.6263\n",
      "Epoch 37/1000\n",
      "111/111 [==============================] - 34s 304ms/step - loss: 40.3122 - weighted_acc: 0.8169 - val_loss: 219.4483 - val_weighted_acc: 0.6326\n",
      "Epoch 38/1000\n",
      "111/111 [==============================] - 34s 304ms/step - loss: 39.3506 - weighted_acc: 0.8182 - val_loss: 220.5348 - val_weighted_acc: 0.6289\n",
      "Epoch 39/1000\n",
      "111/111 [==============================] - 34s 310ms/step - loss: 38.3347 - weighted_acc: 0.8193 - val_loss: 223.6376 - val_weighted_acc: 0.6249\n",
      "Epoch 40/1000\n",
      "111/111 [==============================] - 33s 301ms/step - loss: 37.3756 - weighted_acc: 0.8214 - val_loss: 224.5876 - val_weighted_acc: 0.6251\n",
      "Epoch 41/1000\n",
      "111/111 [==============================] - 34s 302ms/step - loss: 36.7497 - weighted_acc: 0.8222 - val_loss: 225.0119 - val_weighted_acc: 0.6280\n",
      "Epoch 42/1000\n",
      "111/111 [==============================] - 33s 301ms/step - loss: 35.9724 - weighted_acc: 0.8234 - val_loss: 227.3295 - val_weighted_acc: 0.6255\n",
      "Epoch 43/1000\n",
      "111/111 [==============================] - 33s 296ms/step - loss: 35.1650 - weighted_acc: 0.8248 - val_loss: 230.8167 - val_weighted_acc: 0.6266\n",
      "Epoch 44/1000\n",
      "111/111 [==============================] - 33s 298ms/step - loss: 34.4263 - weighted_acc: 0.8257 - val_loss: 234.2422 - val_weighted_acc: 0.6243\n",
      "Epoch 45/1000\n",
      "111/111 [==============================] - 34s 303ms/step - loss: 33.8468 - weighted_acc: 0.8252 - val_loss: 235.7039 - val_weighted_acc: 0.6232\n",
      "Epoch 46/1000\n",
      "111/111 [==============================] - 33s 299ms/step - loss: 33.2334 - weighted_acc: 0.8259 - val_loss: 238.3496 - val_weighted_acc: 0.6215\n",
      "Epoch 47/1000\n",
      "111/111 [==============================] - 34s 304ms/step - loss: 32.1730 - weighted_acc: 0.8305 - val_loss: 241.8485 - val_weighted_acc: 0.6193\n",
      "Epoch 48/1000\n",
      "111/111 [==============================] - 33s 301ms/step - loss: 31.8469 - weighted_acc: 0.8301 - val_loss: 242.4518 - val_weighted_acc: 0.6269\n",
      "Epoch 49/1000\n",
      "111/111 [==============================] - 33s 300ms/step - loss: 31.2856 - weighted_acc: 0.8325 - val_loss: 248.2879 - val_weighted_acc: 0.6196\n",
      "Epoch 50/1000\n",
      "111/111 [==============================] - 33s 299ms/step - loss: 30.6354 - weighted_acc: 0.8319 - val_loss: 252.0332 - val_weighted_acc: 0.6206\n",
      "Epoch 51/1000\n",
      "111/111 [==============================] - 34s 306ms/step - loss: 29.9981 - weighted_acc: 0.8345 - val_loss: 256.7505 - val_weighted_acc: 0.6200\n",
      "Epoch 52/1000\n",
      "111/111 [==============================] - 34s 302ms/step - loss: 29.5235 - weighted_acc: 0.8339 - val_loss: 260.8453 - val_weighted_acc: 0.6195\n",
      "Epoch 53/1000\n",
      "111/111 [==============================] - 33s 299ms/step - loss: 28.9429 - weighted_acc: 0.8369 - val_loss: 267.1733 - val_weighted_acc: 0.6166\n"
     ]
    }
   ],
   "source": [
    "model=run_baseline(epochs=1000, setting_name='cnn_cnnhpss_', gpu='1', train_batch_size=50,\n",
    "                 test_batch_size=50, patience=50, features_to_use=['onehot', 'sequence_profile'], convs=[7,9,11], dense_size=1000, use_CRF=True, filter_size=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
