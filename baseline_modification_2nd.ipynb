{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from models.attention import multihead_model\n",
    "from models.selfattention import selfattention_model, selfattention_model_modified\n",
    "from models.baseline_model import baseline,baseline_preprocess, baseline_residual, baseline_modified\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from data_utility.file_utility import FileUtility\n",
    "from data_utility.labeling_utility import LabelingData\n",
    "import itertools\n",
    "from data_utility.feedgenerator import train_batch_generator_408, validation_batch_generator_408\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_baseline(epochs=10, setting_name='basemodel', gpu='1', train_batch_size=64,\n",
    "                 test_batch_size=100, patience=10, features_to_use=['onehot', 'sequence_profile'], convs=[3, 5, 7], dense_size=200, lstm_size=400,use_CRF=False,filter_size=256):\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "\n",
    "    # read files\n",
    "    train_file = '../DeepSeq2Sec/data/s8_all_features/train.txt'\n",
    "    test_file = '../DeepSeq2Sec/data/s8_all_features/test.txt'\n",
    "    LD = LabelingData(train_file, test_file)\n",
    "    train_lengths = [int(j) for j in FileUtility.load_list('/'.join(train_file.split('/')[0:-1]) + '/train_length.txt')]\n",
    "    test_lengths = [int(i) for i in FileUtility.load_list('/'.join(test_file.split('/')[0:-1]) + '/test_length.txt')]\n",
    "\n",
    "    # model\n",
    "    model, params = baseline_preprocess(LD.n_classes, features_to_use=features_to_use, convs=convs,\n",
    "                             dense_size=dense_size, lstm_size=lstm_size,use_CRF=use_CRF, filter_size=filter_size)\n",
    "\n",
    "    # output directory\n",
    "    FileUtility.ensure_dir('baseline_modifications/' + setting_name + params + '/')\n",
    "\n",
    "    # save model\n",
    "    with open('baseline_modifications/' + setting_name + params + '/' + 'config.txt', 'w') as fh:\n",
    "        model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "\n",
    "    # check points\n",
    "    filepath = 'baseline_modifications/' + setting_name + params + \"/weights-improvement-{epoch:02d}-{weighted_acc:.3f}-{val_weighted_acc:.3f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_weighted_acc', verbose=1, save_best_only=True, mode='max',\n",
    "                                 period=1)\n",
    "    earlystopping = EarlyStopping(monitor='val_weighted_acc', min_delta=0, patience=patience, verbose=0, mode='max',\n",
    "                                  baseline=None)\n",
    "    callbacks_list = [checkpoint, earlystopping]\n",
    "\n",
    "    # calculate the sizes\n",
    "    steps_per_epoch = len(train_lengths) / train_batch_size if len(train_lengths) % train_batch_size == 0 else int(\n",
    "        len(train_lengths) / train_batch_size) + 1\n",
    "    validation_steps = int(len(test_lengths) / test_batch_size) if len(test_lengths) % test_batch_size == 0 else int(\n",
    "        len(test_lengths) / test_batch_size) + 1\n",
    "\n",
    "    # feed model\n",
    "    h = model.fit_generator(train_batch_generator_408(train_batch_size), steps_per_epoch=steps_per_epoch,\n",
    "                            validation_data=validation_batch_generator_408(test_batch_size),\n",
    "                            validation_steps=validation_steps,\n",
    "                            shuffle=False, epochs=epochs, verbose=1, callbacks=callbacks_list)\n",
    "\n",
    "    # save the history\n",
    "    FileUtility.save_obj('baseline_modifications/' + setting_name + params + '/history', h.history)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling utility object created..\n",
      "Training y encoded shape is  (5534, 700)\n",
      "Maximum sequence length is 700\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 408)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "onehot (Lambda)                 (None, None, 21)     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequenceprofile (Lambda)        (None, None, 21)     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, 21)     84          onehot[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, 21)     84          sequenceprofile[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 21)     462         batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 21)     462         batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 42)     0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv1D)                  (None, None, 256)    32512       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv1D)                  (None, None, 256)    54016       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv1D)                  (None, None, 256)    75520       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv1D)                  (None, None, 256)    118528      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Conv1D)                  (None, None, 256)    226048      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_conv1 (BatchNormaliz (None, None, 256)    1024        conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_conv2 (BatchNormaliz (None, None, 256)    1024        conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_conv3 (BatchNormaliz (None, None, 256)    1024        conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_conv4 (BatchNormaliz (None, None, 256)    1024        conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_conv5 (BatchNormaliz (None, None, 256)    1024        conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, 1322)   0           concatenate_1[0][0]              \n",
      "                                                                 batch_norm_conv1[0][0]           \n",
      "                                                                 batch_norm_conv2[0][0]           \n",
      "                                                                 batch_norm_conv3[0][0]           \n",
      "                                                                 batch_norm_conv4[0][0]           \n",
      "                                                                 batch_norm_conv5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropoutonconvs (Dropout)        (None, None, 1322)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "denseonconvs (Dense)            (None, None, 1000)   1323000     dropoutonconvs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_dense (BatchNormaliz (None, None, 1000)   4000        denseonconvs[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 2000)   16016000    batch_norm_dense[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 2000)   0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 1000)   2001000     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 9)      9009        dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 19,865,845\n",
      "Trainable params: 19,861,201\n",
      "Non-trainable params: 4,644\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/1000\n",
      "87/87 [==============================] - 71s 820ms/step - loss: 1.3673 - weighted_acc: 0.6166 - val_loss: 1.2711 - val_weighted_acc: 0.6200\n",
      "\n",
      "Epoch 00001: val_weighted_acc improved from -inf to 0.62005, saving model to baseline_modifications/profilesig_onehotembed_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_256/weights-improvement-01-0.617-0.620.hdf5\n",
      "Epoch 2/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 1.0222 - weighted_acc: 0.6909 - val_loss: 1.2482 - val_weighted_acc: 0.6004\n",
      "\n",
      "Epoch 00002: val_weighted_acc did not improve from 0.62005\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.9008 - weighted_acc: 0.7084 - val_loss: 1.2321 - val_weighted_acc: 0.5986\n",
      "\n",
      "Epoch 00003: val_weighted_acc did not improve from 0.62005\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.8374 - weighted_acc: 0.7190 - val_loss: 1.1400 - val_weighted_acc: 0.6300\n",
      "\n",
      "Epoch 00004: val_weighted_acc improved from 0.62005 to 0.63002, saving model to baseline_modifications/profilesig_onehotembed_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_256/weights-improvement-04-0.719-0.630.hdf5\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.7981 - weighted_acc: 0.7275 - val_loss: 1.1185 - val_weighted_acc: 0.6168\n",
      "\n",
      "Epoch 00005: val_weighted_acc did not improve from 0.63002\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.7678 - weighted_acc: 0.7351 - val_loss: 1.0684 - val_weighted_acc: 0.6373\n",
      "\n",
      "Epoch 00006: val_weighted_acc improved from 0.63002 to 0.63728, saving model to baseline_modifications/profilesig_onehotembed_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_256/weights-improvement-06-0.735-0.637.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000\n",
      "87/87 [==============================] - 24s 274ms/step - loss: 0.7518 - weighted_acc: 0.7396 - val_loss: 1.0791 - val_weighted_acc: 0.6290\n",
      "\n",
      "Epoch 00007: val_weighted_acc did not improve from 0.63728\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.7338 - weighted_acc: 0.7450 - val_loss: 1.0990 - val_weighted_acc: 0.6301\n",
      "\n",
      "Epoch 00008: val_weighted_acc did not improve from 0.63728\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 24s 274ms/step - loss: 0.7294 - weighted_acc: 0.7473 - val_loss: 1.0006 - val_weighted_acc: 0.6619\n",
      "\n",
      "Epoch 00009: val_weighted_acc improved from 0.63728 to 0.66187, saving model to baseline_modifications/profilesig_onehotembed_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_256/weights-improvement-09-0.748-0.662.hdf5\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 24s 274ms/step - loss: 0.6976 - weighted_acc: 0.7571 - val_loss: 1.0206 - val_weighted_acc: 0.6532\n",
      "\n",
      "Epoch 00010: val_weighted_acc did not improve from 0.66187\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.6697 - weighted_acc: 0.7658 - val_loss: 1.0391 - val_weighted_acc: 0.6507\n",
      "\n",
      "Epoch 00011: val_weighted_acc did not improve from 0.66187\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 24s 274ms/step - loss: 0.6535 - weighted_acc: 0.7722 - val_loss: 0.9786 - val_weighted_acc: 0.6705\n",
      "\n",
      "Epoch 00012: val_weighted_acc improved from 0.66187 to 0.67045, saving model to baseline_modifications/profilesig_onehotembed_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_256/weights-improvement-12-0.773-0.670.hdf5\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.6310 - weighted_acc: 0.7794 - val_loss: 0.9730 - val_weighted_acc: 0.6725\n",
      "\n",
      "Epoch 00013: val_weighted_acc improved from 0.67045 to 0.67250, saving model to baseline_modifications/profilesig_onehotembed_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_256/weights-improvement-13-0.780-0.673.hdf5\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.6157 - weighted_acc: 0.7855 - val_loss: 0.9382 - val_weighted_acc: 0.6842\n",
      "\n",
      "Epoch 00014: val_weighted_acc improved from 0.67250 to 0.68422, saving model to baseline_modifications/profilesig_onehotembed_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_256/weights-improvement-14-0.786-0.684.hdf5\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.6083 - weighted_acc: 0.7885 - val_loss: 0.9375 - val_weighted_acc: 0.6839\n",
      "\n",
      "Epoch 00015: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.5918 - weighted_acc: 0.7950 - val_loss: 0.9596 - val_weighted_acc: 0.6774\n",
      "\n",
      "Epoch 00016: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.5653 - weighted_acc: 0.8036 - val_loss: 0.9495 - val_weighted_acc: 0.6801\n",
      "\n",
      "Epoch 00017: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.5412 - weighted_acc: 0.8116 - val_loss: 1.0306 - val_weighted_acc: 0.6579\n",
      "\n",
      "Epoch 00018: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.5283 - weighted_acc: 0.8168 - val_loss: 0.9904 - val_weighted_acc: 0.6743\n",
      "\n",
      "Epoch 00019: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.5154 - weighted_acc: 0.8216 - val_loss: 0.9945 - val_weighted_acc: 0.6736\n",
      "\n",
      "Epoch 00020: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.4922 - weighted_acc: 0.8302 - val_loss: 0.9981 - val_weighted_acc: 0.6721\n",
      "\n",
      "Epoch 00021: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.4683 - weighted_acc: 0.8387 - val_loss: 1.0106 - val_weighted_acc: 0.6766\n",
      "\n",
      "Epoch 00022: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.4525 - weighted_acc: 0.8445 - val_loss: 1.0162 - val_weighted_acc: 0.6715\n",
      "\n",
      "Epoch 00023: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.4350 - weighted_acc: 0.8512 - val_loss: 1.0055 - val_weighted_acc: 0.6792\n",
      "\n",
      "Epoch 00024: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.4239 - weighted_acc: 0.8546 - val_loss: 1.0344 - val_weighted_acc: 0.6762\n",
      "\n",
      "Epoch 00025: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.4172 - weighted_acc: 0.8575 - val_loss: 1.0431 - val_weighted_acc: 0.6715\n",
      "\n",
      "Epoch 00026: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.4116 - weighted_acc: 0.8596 - val_loss: 1.0502 - val_weighted_acc: 0.6786\n",
      "\n",
      "Epoch 00027: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.4055 - weighted_acc: 0.8623 - val_loss: 1.0491 - val_weighted_acc: 0.6696\n",
      "\n",
      "Epoch 00028: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.3892 - weighted_acc: 0.8685 - val_loss: 1.0889 - val_weighted_acc: 0.6607\n",
      "\n",
      "Epoch 00029: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.3698 - weighted_acc: 0.8757 - val_loss: 1.1269 - val_weighted_acc: 0.6575\n",
      "\n",
      "Epoch 00030: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.3502 - weighted_acc: 0.8824 - val_loss: 1.1169 - val_weighted_acc: 0.6639\n",
      "\n",
      "Epoch 00031: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.3389 - weighted_acc: 0.8866 - val_loss: 1.2048 - val_weighted_acc: 0.6510\n",
      "\n",
      "Epoch 00032: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.3346 - weighted_acc: 0.8885 - val_loss: 1.1676 - val_weighted_acc: 0.6688\n",
      "\n",
      "Epoch 00033: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.3267 - weighted_acc: 0.8919 - val_loss: 1.1580 - val_weighted_acc: 0.6598\n",
      "\n",
      "Epoch 00034: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.3164 - weighted_acc: 0.8955 - val_loss: 1.2135 - val_weighted_acc: 0.6488\n",
      "\n",
      "Epoch 00035: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.3068 - weighted_acc: 0.8989 - val_loss: 1.2192 - val_weighted_acc: 0.6541\n",
      "\n",
      "Epoch 00036: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.2976 - weighted_acc: 0.9024 - val_loss: 1.2443 - val_weighted_acc: 0.6601\n",
      "\n",
      "Epoch 00037: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.2875 - weighted_acc: 0.9062 - val_loss: 1.2365 - val_weighted_acc: 0.6643\n",
      "\n",
      "Epoch 00038: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.2799 - weighted_acc: 0.9088 - val_loss: 1.2301 - val_weighted_acc: 0.6637\n",
      "\n",
      "Epoch 00039: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.2730 - weighted_acc: 0.9115 - val_loss: 1.2476 - val_weighted_acc: 0.6549\n",
      "\n",
      "Epoch 00040: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.2671 - weighted_acc: 0.9137 - val_loss: 1.3050 - val_weighted_acc: 0.6447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00041: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.2619 - weighted_acc: 0.9154 - val_loss: 1.3289 - val_weighted_acc: 0.6381\n",
      "\n",
      "Epoch 00042: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.2547 - weighted_acc: 0.9183 - val_loss: 1.3627 - val_weighted_acc: 0.6324\n",
      "\n",
      "Epoch 00043: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.2532 - weighted_acc: 0.9191 - val_loss: 1.3907 - val_weighted_acc: 0.6433\n",
      "\n",
      "Epoch 00044: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.2528 - weighted_acc: 0.9196 - val_loss: 1.3460 - val_weighted_acc: 0.6425\n",
      "\n",
      "Epoch 00045: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.2495 - weighted_acc: 0.9207 - val_loss: 1.3504 - val_weighted_acc: 0.6420\n",
      "\n",
      "Epoch 00046: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.2458 - weighted_acc: 0.9221 - val_loss: 1.3433 - val_weighted_acc: 0.6392\n",
      "\n",
      "Epoch 00047: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.2390 - weighted_acc: 0.9251 - val_loss: 1.3406 - val_weighted_acc: 0.6371\n",
      "\n",
      "Epoch 00048: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.2309 - weighted_acc: 0.9281 - val_loss: 1.3155 - val_weighted_acc: 0.6406\n",
      "\n",
      "Epoch 00049: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.2230 - weighted_acc: 0.9310 - val_loss: 1.3630 - val_weighted_acc: 0.6315\n",
      "\n",
      "Epoch 00050: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.2164 - weighted_acc: 0.9331 - val_loss: 1.3814 - val_weighted_acc: 0.6323\n",
      "\n",
      "Epoch 00051: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.2112 - weighted_acc: 0.9350 - val_loss: 1.3846 - val_weighted_acc: 0.6345\n",
      "\n",
      "Epoch 00052: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.2081 - weighted_acc: 0.9363 - val_loss: 1.4281 - val_weighted_acc: 0.6204\n",
      "\n",
      "Epoch 00053: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.2038 - weighted_acc: 0.9377 - val_loss: 1.4672 - val_weighted_acc: 0.6033\n",
      "\n",
      "Epoch 00054: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.2000 - weighted_acc: 0.9392 - val_loss: 1.4317 - val_weighted_acc: 0.6236\n",
      "\n",
      "Epoch 00055: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1966 - weighted_acc: 0.9406 - val_loss: 1.4959 - val_weighted_acc: 0.6184\n",
      "\n",
      "Epoch 00056: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.1966 - weighted_acc: 0.9407 - val_loss: 1.4445 - val_weighted_acc: 0.6187\n",
      "\n",
      "Epoch 00057: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1952 - weighted_acc: 0.9413 - val_loss: 1.4028 - val_weighted_acc: 0.6318\n",
      "\n",
      "Epoch 00058: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.1905 - weighted_acc: 0.9431 - val_loss: 1.4487 - val_weighted_acc: 0.6234\n",
      "\n",
      "Epoch 00059: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1852 - weighted_acc: 0.9448 - val_loss: 1.5037 - val_weighted_acc: 0.6271\n",
      "\n",
      "Epoch 00060: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1853 - weighted_acc: 0.9452 - val_loss: 1.5239 - val_weighted_acc: 0.6341\n",
      "\n",
      "Epoch 00061: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1805 - weighted_acc: 0.9469 - val_loss: 1.5460 - val_weighted_acc: 0.6357\n",
      "\n",
      "Epoch 00062: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1783 - weighted_acc: 0.9474 - val_loss: 1.4808 - val_weighted_acc: 0.6486\n",
      "\n",
      "Epoch 00063: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.1738 - weighted_acc: 0.9488 - val_loss: 1.5711 - val_weighted_acc: 0.6406\n",
      "\n",
      "Epoch 00064: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1724 - weighted_acc: 0.9496 - val_loss: 1.5484 - val_weighted_acc: 0.6368\n",
      "\n",
      "Epoch 00065: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.1676 - weighted_acc: 0.9514 - val_loss: 1.6080 - val_weighted_acc: 0.6204\n",
      "\n",
      "Epoch 00066: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.1638 - weighted_acc: 0.9527 - val_loss: 1.5103 - val_weighted_acc: 0.6519\n",
      "\n",
      "Epoch 00067: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1595 - weighted_acc: 0.9542 - val_loss: 1.5134 - val_weighted_acc: 0.6604\n",
      "\n",
      "Epoch 00068: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1577 - weighted_acc: 0.9549 - val_loss: 1.5926 - val_weighted_acc: 0.6622\n",
      "\n",
      "Epoch 00069: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1552 - weighted_acc: 0.9557 - val_loss: 1.6594 - val_weighted_acc: 0.6639\n",
      "\n",
      "Epoch 00070: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.1545 - weighted_acc: 0.9563 - val_loss: 1.7038 - val_weighted_acc: 0.6621\n",
      "\n",
      "Epoch 00071: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1554 - weighted_acc: 0.9557 - val_loss: 1.7211 - val_weighted_acc: 0.6632\n",
      "\n",
      "Epoch 00072: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1543 - weighted_acc: 0.9563 - val_loss: 1.7219 - val_weighted_acc: 0.6604\n",
      "\n",
      "Epoch 00073: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.1562 - weighted_acc: 0.9558 - val_loss: 1.6979 - val_weighted_acc: 0.6610\n",
      "\n",
      "Epoch 00074: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.1547 - weighted_acc: 0.9565 - val_loss: 1.6516 - val_weighted_acc: 0.6544\n",
      "\n",
      "Epoch 00075: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.1547 - weighted_acc: 0.9564 - val_loss: 1.6150 - val_weighted_acc: 0.6465\n",
      "\n",
      "Epoch 00076: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 24s 275ms/step - loss: 0.1538 - weighted_acc: 0.9567 - val_loss: 1.6061 - val_weighted_acc: 0.6507\n",
      "\n",
      "Epoch 00077: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1503 - weighted_acc: 0.9581 - val_loss: 1.6523 - val_weighted_acc: 0.6395\n",
      "\n",
      "Epoch 00078: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 24s 270ms/step - loss: 0.1496 - weighted_acc: 0.9587 - val_loss: 1.6947 - val_weighted_acc: 0.6579\n",
      "\n",
      "Epoch 00079: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 24s 273ms/step - loss: 0.1464 - weighted_acc: 0.9598 - val_loss: 1.6958 - val_weighted_acc: 0.6620\n",
      "\n",
      "Epoch 00080: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.1426 - weighted_acc: 0.9609 - val_loss: 1.7441 - val_weighted_acc: 0.6675\n",
      "\n",
      "Epoch 00081: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.1389 - weighted_acc: 0.9620 - val_loss: 1.7548 - val_weighted_acc: 0.6651\n",
      "\n",
      "Epoch 00082: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.1373 - weighted_acc: 0.9627 - val_loss: 1.7598 - val_weighted_acc: 0.6661\n",
      "\n",
      "Epoch 00083: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.1337 - weighted_acc: 0.9639 - val_loss: 1.6882 - val_weighted_acc: 0.6651\n",
      "\n",
      "Epoch 00084: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.1316 - weighted_acc: 0.9646 - val_loss: 1.6974 - val_weighted_acc: 0.6649\n",
      "\n",
      "Epoch 00085: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1281 - weighted_acc: 0.9656 - val_loss: 1.6926 - val_weighted_acc: 0.6627\n",
      "\n",
      "Epoch 00086: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.1260 - weighted_acc: 0.9664 - val_loss: 1.7109 - val_weighted_acc: 0.6625\n",
      "\n",
      "Epoch 00087: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 24s 270ms/step - loss: 0.1236 - weighted_acc: 0.9673 - val_loss: 1.7715 - val_weighted_acc: 0.6590\n",
      "\n",
      "Epoch 00088: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 23s 270ms/step - loss: 0.1235 - weighted_acc: 0.9672 - val_loss: 1.7131 - val_weighted_acc: 0.6621\n",
      "\n",
      "Epoch 00089: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1223 - weighted_acc: 0.9676 - val_loss: 1.8165 - val_weighted_acc: 0.6563\n",
      "\n",
      "Epoch 00090: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.1211 - weighted_acc: 0.9682 - val_loss: 1.8287 - val_weighted_acc: 0.6575\n",
      "\n",
      "Epoch 00091: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1195 - weighted_acc: 0.9687 - val_loss: 1.8050 - val_weighted_acc: 0.6592\n",
      "\n",
      "Epoch 00092: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1185 - weighted_acc: 0.9688 - val_loss: 1.8244 - val_weighted_acc: 0.6615\n",
      "\n",
      "Epoch 00093: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1164 - weighted_acc: 0.9696 - val_loss: 1.8195 - val_weighted_acc: 0.6613\n",
      "\n",
      "Epoch 00094: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.1143 - weighted_acc: 0.9704 - val_loss: 1.8271 - val_weighted_acc: 0.6665\n",
      "\n",
      "Epoch 00095: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.1120 - weighted_acc: 0.9710 - val_loss: 1.8287 - val_weighted_acc: 0.6644\n",
      "\n",
      "Epoch 00096: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1095 - weighted_acc: 0.9717 - val_loss: 1.8546 - val_weighted_acc: 0.6617\n",
      "\n",
      "Epoch 00097: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1077 - weighted_acc: 0.9725 - val_loss: 1.8773 - val_weighted_acc: 0.6651\n",
      "\n",
      "Epoch 00098: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1071 - weighted_acc: 0.9726 - val_loss: 1.8135 - val_weighted_acc: 0.6575\n",
      "\n",
      "Epoch 00099: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 24s 274ms/step - loss: 0.1050 - weighted_acc: 0.9733 - val_loss: 1.8122 - val_weighted_acc: 0.6549\n",
      "\n",
      "Epoch 00100: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1039 - weighted_acc: 0.9735 - val_loss: 1.8909 - val_weighted_acc: 0.6399\n",
      "\n",
      "Epoch 00101: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 102/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.1022 - weighted_acc: 0.9743 - val_loss: 1.8697 - val_weighted_acc: 0.6425\n",
      "\n",
      "Epoch 00102: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 103/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.1012 - weighted_acc: 0.9746 - val_loss: 1.9006 - val_weighted_acc: 0.6511\n",
      "\n",
      "Epoch 00103: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 104/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.0990 - weighted_acc: 0.9755 - val_loss: 1.8786 - val_weighted_acc: 0.6552\n",
      "\n",
      "Epoch 00104: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 105/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1002 - weighted_acc: 0.9752 - val_loss: 1.8927 - val_weighted_acc: 0.6526\n",
      "\n",
      "Epoch 00105: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 106/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.0994 - weighted_acc: 0.9754 - val_loss: 1.9111 - val_weighted_acc: 0.6532\n",
      "\n",
      "Epoch 00106: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 107/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1008 - weighted_acc: 0.9750 - val_loss: 1.8565 - val_weighted_acc: 0.6586\n",
      "\n",
      "Epoch 00107: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 108/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1013 - weighted_acc: 0.9749 - val_loss: 1.9036 - val_weighted_acc: 0.6594\n",
      "\n",
      "Epoch 00108: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 109/1000\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 0.1001 - weighted_acc: 0.9753 - val_loss: 1.9501 - val_weighted_acc: 0.6548\n",
      "\n",
      "Epoch 00109: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 110/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1007 - weighted_acc: 0.9751 - val_loss: 1.9619 - val_weighted_acc: 0.6542\n",
      "\n",
      "Epoch 00110: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 111/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1025 - weighted_acc: 0.9744 - val_loss: 1.9578 - val_weighted_acc: 0.6467\n",
      "\n",
      "Epoch 00111: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 112/1000\n",
      "87/87 [==============================] - 24s 270ms/step - loss: 0.1040 - weighted_acc: 0.9740 - val_loss: 1.9245 - val_weighted_acc: 0.6321\n",
      "\n",
      "Epoch 00112: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 113/1000\n",
      "87/87 [==============================] - 24s 271ms/step - loss: 0.1039 - weighted_acc: 0.9739 - val_loss: 1.9398 - val_weighted_acc: 0.6318\n",
      "\n",
      "Epoch 00113: val_weighted_acc did not improve from 0.68422\n",
      "Epoch 114/1000\n",
      "87/87 [==============================] - 24s 272ms/step - loss: 0.1053 - weighted_acc: 0.9738 - val_loss: 1.9009 - val_weighted_acc: 0.6450\n",
      "\n",
      "Epoch 00114: val_weighted_acc did not improve from 0.68422\n"
     ]
    }
   ],
   "source": [
    "model=run_baseline(epochs=1000, setting_name='profilesig_onehotembed_', gpu='0', train_batch_size=64,\n",
    "                 test_batch_size=100, patience=100, features_to_use=['onehot', 'sequence_profile'], convs=[3,5,7,11,21], dense_size=1000, lstm_size=1000,use_CRF=False, filter_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=run_baseline(epochs=1000, setting_name='baseline_no_cnn', gpu='1', train_batch_size=64,\n",
    "                 test_batch_size=100, patience=50, features_to_use=['onehot', 'sequence_profile'], convs=[3,5,7,11,21], dense_size=200, lstm_size=200,use_CRF=False, filter_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
