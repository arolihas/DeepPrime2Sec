{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from models.attention import multihead_model\n",
    "from models.selfattention import selfattention_model, selfattention_model_modified\n",
    "from models.baseline_model import baseline, baseline_residual, baseline_modified\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from data_utility.file_utility import FileUtility\n",
    "from data_utility.labeling_utility import LabelingData\n",
    "import itertools\n",
    "from data_utility.feedgenerator import train_batch_generator_408, validation_batch_generator_408\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_baseline(epochs=10, setting_name='basemodel', gpu='1', train_batch_size=64,\n",
    "                 test_batch_size=100, patience=10, features_to_use=['onehot', 'sequence_profile'], convs=[3, 5, 7], dense_size=200, lstm_size=400,use_CRF=False):\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "\n",
    "    # read files\n",
    "    train_file = '../DeepSeq2Sec/data/s8_all_features/train.txt'\n",
    "    test_file = '../DeepSeq2Sec/data/s8_all_features/test.txt'\n",
    "    LD = LabelingData(train_file, test_file)\n",
    "    train_lengths = [int(j) for j in FileUtility.load_list('/'.join(train_file.split('/')[0:-1]) + '/train_length.txt')]\n",
    "    test_lengths = [int(i) for i in FileUtility.load_list('/'.join(test_file.split('/')[0:-1]) + '/test_length.txt')]\n",
    "\n",
    "    # model\n",
    "    model, params = baseline_residual(LD.n_classes, features_to_use=features_to_use, convs=convs,\n",
    "                             dense_size=dense_size, lstm_size=lstm_size,use_CRF=use_CRF)\n",
    "\n",
    "    # output directory\n",
    "    FileUtility.ensure_dir('baseline_modifications/' + setting_name + params + '/')\n",
    "\n",
    "    # save model\n",
    "    with open('baseline_modifications/' + setting_name + params + '/' + 'config.txt', 'w') as fh:\n",
    "        model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "\n",
    "    # check points\n",
    "    filepath = 'baseline_modifications/' + setting_name + params + \"/weights-improvement-{epoch:02d}-{weighted_acc:.3f}-{val_weighted_acc:.3f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_weighted_acc', verbose=1, save_best_only=True, mode='max',\n",
    "                                 period=1)\n",
    "    earlystopping = EarlyStopping(monitor='val_weighted_acc', min_delta=0, patience=patience, verbose=0, mode='max',\n",
    "                                  baseline=None)\n",
    "    callbacks_list = [checkpoint, earlystopping]\n",
    "\n",
    "    # calculate the sizes\n",
    "    steps_per_epoch = len(train_lengths) / train_batch_size if len(train_lengths) % train_batch_size == 0 else int(\n",
    "        len(train_lengths) / train_batch_size) + 1\n",
    "    validation_steps = int(len(test_lengths) / test_batch_size) if len(test_lengths) % test_batch_size == 0 else int(\n",
    "        len(test_lengths) / test_batch_size) + 1\n",
    "\n",
    "    # feed model\n",
    "    h = model.fit_generator(train_batch_generator_408(train_batch_size), steps_per_epoch=steps_per_epoch,\n",
    "                            validation_data=validation_batch_generator_408(test_batch_size),\n",
    "                            validation_steps=validation_steps,\n",
    "                            shuffle=False, epochs=epochs, verbose=1, callbacks=callbacks_list)\n",
    "\n",
    "    # save the history\n",
    "    FileUtility.save_obj('baseline_modifications/' + setting_name + params + '/history', h.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling utility object created..\n",
      "Training y encoded shape is  (5534, 700)\n",
      "Maximum sequence length is 700\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, 408)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "onehot (Lambda)                 (None, None, 21)     0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequenceprofile (Lambda)        (None, None, 21)     0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, None, 42)     0           onehot[0][0]                     \n",
      "                                                                 sequenceprofile[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batchnorm_input (BatchNormaliza (None, None, 42)     168         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv1D)                  (None, None, 32)     4064        batchnorm_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv1D)                  (None, None, 32)     6752        batchnorm_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv1D)                  (None, None, 32)     9440        batchnorm_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv1D)                  (None, None, 32)     14816       batchnorm_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Conv1D)                  (None, None, 32)     28256       batchnorm_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_conv1 (BatchNormaliz (None, None, 32)     128         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_conv2 (BatchNormaliz (None, None, 32)     128         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_conv3 (BatchNormaliz (None, None, 32)     128         conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_conv4 (BatchNormaliz (None, None, 32)     128         conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_conv5 (BatchNormaliz (None, None, 32)     128         conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, None, 202)    0           batchnorm_input[0][0]            \n",
      "                                                                 batch_norm_conv1[0][0]           \n",
      "                                                                 batch_norm_conv2[0][0]           \n",
      "                                                                 batch_norm_conv3[0][0]           \n",
      "                                                                 batch_norm_conv4[0][0]           \n",
      "                                                                 batch_norm_conv5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropoutonconvs (Dropout)        (None, None, 202)    0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "denseonconvs (Dense)            (None, None, 1000)   203000      dropoutonconvs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_dense (BatchNormaliz (None, None, 1000)   4000        denseonconvs[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 2000)   16016000    batch_norm_dense[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 2000)   0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batchnormseqprof (BatchNormaliz (None, None, 21)     84          sequenceprofile[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, None, 2021)   0           dropout_2[0][0]                  \n",
      "                                                                 batchnormseqprof[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 9)      18198       concatenate_6[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 16,305,418\n",
      "Trainable params: 16,302,972\n",
      "Non-trainable params: 2,446\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "173/173 [==============================] - 53s 304ms/step - loss: 1.4191 - weighted_acc: 0.6384 - val_loss: 1.1322 - val_weighted_acc: 0.6349\n",
      "\n",
      "Epoch 00001: val_weighted_acc improved from -inf to 0.63488, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-01-0.638-0.635.hdf5\n",
      "Epoch 2/300\n",
      "173/173 [==============================] - 29s 170ms/step - loss: 0.9887 - weighted_acc: 0.6851 - val_loss: 1.0503 - val_weighted_acc: 0.6428\n",
      "\n",
      "Epoch 00002: val_weighted_acc improved from 0.63488 to 0.64278, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-02-0.685-0.643.hdf5\n",
      "Epoch 3/300\n",
      "173/173 [==============================] - 29s 169ms/step - loss: 0.9114 - weighted_acc: 0.6989 - val_loss: 1.0037 - val_weighted_acc: 0.6526\n",
      "\n",
      "Epoch 00003: val_weighted_acc improved from 0.64278 to 0.65263, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-03-0.699-0.653.hdf5\n",
      "Epoch 4/300\n",
      "173/173 [==============================] - 29s 170ms/step - loss: 0.8701 - weighted_acc: 0.7074 - val_loss: 0.9747 - val_weighted_acc: 0.6600\n",
      "\n",
      "Epoch 00004: val_weighted_acc improved from 0.65263 to 0.66003, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-04-0.707-0.660.hdf5\n",
      "Epoch 5/300\n",
      "173/173 [==============================] - 29s 170ms/step - loss: 0.8465 - weighted_acc: 0.7124 - val_loss: 0.9522 - val_weighted_acc: 0.6680\n",
      "\n",
      "Epoch 00005: val_weighted_acc improved from 0.66003 to 0.66799, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-05-0.712-0.668.hdf5\n",
      "Epoch 6/300\n",
      "173/173 [==============================] - 30s 171ms/step - loss: 0.8322 - weighted_acc: 0.7158 - val_loss: 0.9432 - val_weighted_acc: 0.6698\n",
      "\n",
      "Epoch 00006: val_weighted_acc improved from 0.66799 to 0.66981, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-06-0.716-0.670.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/300\n",
      "173/173 [==============================] - 29s 170ms/step - loss: 0.8212 - weighted_acc: 0.7188 - val_loss: 0.9305 - val_weighted_acc: 0.6754\n",
      "\n",
      "Epoch 00007: val_weighted_acc improved from 0.66981 to 0.67542, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-07-0.719-0.675.hdf5\n",
      "Epoch 8/300\n",
      "173/173 [==============================] - 30s 171ms/step - loss: 0.8108 - weighted_acc: 0.7219 - val_loss: 0.9309 - val_weighted_acc: 0.6745\n",
      "\n",
      "Epoch 00008: val_weighted_acc did not improve from 0.67542\n",
      "Epoch 9/300\n",
      "173/173 [==============================] - 30s 171ms/step - loss: 0.8049 - weighted_acc: 0.7236 - val_loss: 0.9229 - val_weighted_acc: 0.6780\n",
      "\n",
      "Epoch 00009: val_weighted_acc improved from 0.67542 to 0.67800, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-09-0.724-0.678.hdf5\n",
      "Epoch 10/300\n",
      "173/173 [==============================] - 29s 169ms/step - loss: 0.7983 - weighted_acc: 0.7253 - val_loss: 0.9216 - val_weighted_acc: 0.6780\n",
      "\n",
      "Epoch 00010: val_weighted_acc improved from 0.67800 to 0.67801, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-10-0.725-0.678.hdf5\n",
      "Epoch 11/300\n",
      "173/173 [==============================] - 29s 169ms/step - loss: 0.7924 - weighted_acc: 0.7273 - val_loss: 0.9173 - val_weighted_acc: 0.6819\n",
      "\n",
      "Epoch 00011: val_weighted_acc improved from 0.67801 to 0.68192, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-11-0.727-0.682.hdf5\n",
      "Epoch 12/300\n",
      "173/173 [==============================] - 29s 170ms/step - loss: 0.7884 - weighted_acc: 0.7290 - val_loss: 0.9182 - val_weighted_acc: 0.6796\n",
      "\n",
      "Epoch 00012: val_weighted_acc did not improve from 0.68192\n",
      "Epoch 13/300\n",
      "173/173 [==============================] - 29s 170ms/step - loss: 0.7827 - weighted_acc: 0.7311 - val_loss: 0.9149 - val_weighted_acc: 0.6813\n",
      "\n",
      "Epoch 00013: val_weighted_acc did not improve from 0.68192\n",
      "Epoch 14/300\n",
      "173/173 [==============================] - 29s 170ms/step - loss: 0.7777 - weighted_acc: 0.7329 - val_loss: 0.9091 - val_weighted_acc: 0.6830\n",
      "\n",
      "Epoch 00014: val_weighted_acc improved from 0.68192 to 0.68299, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-14-0.733-0.683.hdf5\n",
      "Epoch 15/300\n",
      "173/173 [==============================] - 30s 171ms/step - loss: 0.7726 - weighted_acc: 0.7339 - val_loss: 0.9051 - val_weighted_acc: 0.6846\n",
      "\n",
      "Epoch 00015: val_weighted_acc improved from 0.68299 to 0.68461, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-15-0.734-0.685.hdf5\n",
      "Epoch 16/300\n",
      "173/173 [==============================] - 29s 170ms/step - loss: 0.7696 - weighted_acc: 0.7353 - val_loss: 0.9070 - val_weighted_acc: 0.6852\n",
      "\n",
      "Epoch 00016: val_weighted_acc improved from 0.68461 to 0.68516, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-16-0.735-0.685.hdf5\n",
      "Epoch 17/300\n",
      "173/173 [==============================] - 29s 170ms/step - loss: 0.7653 - weighted_acc: 0.7368 - val_loss: 0.9078 - val_weighted_acc: 0.6845\n",
      "\n",
      "Epoch 00017: val_weighted_acc did not improve from 0.68516\n",
      "Epoch 18/300\n",
      "173/173 [==============================] - 29s 168ms/step - loss: 0.7618 - weighted_acc: 0.7384 - val_loss: 0.9077 - val_weighted_acc: 0.6858\n",
      "\n",
      "Epoch 00018: val_weighted_acc improved from 0.68516 to 0.68580, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-18-0.738-0.686.hdf5\n",
      "Epoch 19/300\n",
      "173/173 [==============================] - 29s 169ms/step - loss: 0.7596 - weighted_acc: 0.7389 - val_loss: 0.9064 - val_weighted_acc: 0.6858\n",
      "\n",
      "Epoch 00019: val_weighted_acc did not improve from 0.68580\n",
      "Epoch 20/300\n",
      "173/173 [==============================] - 29s 169ms/step - loss: 0.7546 - weighted_acc: 0.7409 - val_loss: 0.9078 - val_weighted_acc: 0.6842\n",
      "\n",
      "Epoch 00020: val_weighted_acc did not improve from 0.68580\n",
      "Epoch 21/300\n",
      "173/173 [==============================] - 29s 168ms/step - loss: 0.7518 - weighted_acc: 0.7417 - val_loss: 0.9079 - val_weighted_acc: 0.6846\n",
      "\n",
      "Epoch 00021: val_weighted_acc did not improve from 0.68580\n",
      "Epoch 22/300\n",
      "173/173 [==============================] - 29s 168ms/step - loss: 0.7478 - weighted_acc: 0.7428 - val_loss: 0.9078 - val_weighted_acc: 0.6851\n",
      "\n",
      "Epoch 00022: val_weighted_acc did not improve from 0.68580\n",
      "Epoch 23/300\n",
      "173/173 [==============================] - 29s 169ms/step - loss: 0.7454 - weighted_acc: 0.7441 - val_loss: 0.9138 - val_weighted_acc: 0.6817\n",
      "\n",
      "Epoch 00023: val_weighted_acc did not improve from 0.68580\n",
      "Epoch 24/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.7413 - weighted_acc: 0.7457 - val_loss: 0.9133 - val_weighted_acc: 0.6818\n",
      "\n",
      "Epoch 00024: val_weighted_acc did not improve from 0.68580\n",
      "Epoch 25/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.7397 - weighted_acc: 0.7461 - val_loss: 0.9084 - val_weighted_acc: 0.6854\n",
      "\n",
      "Epoch 00025: val_weighted_acc did not improve from 0.68580\n",
      "Epoch 26/300\n",
      "173/173 [==============================] - 29s 169ms/step - loss: 0.7356 - weighted_acc: 0.7473 - val_loss: 0.9050 - val_weighted_acc: 0.6868\n",
      "\n",
      "Epoch 00026: val_weighted_acc improved from 0.68580 to 0.68679, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-26-0.747-0.687.hdf5\n",
      "Epoch 27/300\n",
      "173/173 [==============================] - 29s 168ms/step - loss: 0.7316 - weighted_acc: 0.7490 - val_loss: 0.9040 - val_weighted_acc: 0.6864\n",
      "\n",
      "Epoch 00027: val_weighted_acc did not improve from 0.68679\n",
      "Epoch 28/300\n",
      "173/173 [==============================] - 29s 168ms/step - loss: 0.7290 - weighted_acc: 0.7504 - val_loss: 0.9050 - val_weighted_acc: 0.6874\n",
      "\n",
      "Epoch 00028: val_weighted_acc improved from 0.68679 to 0.68736, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-28-0.750-0.687.hdf5\n",
      "Epoch 29/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.7264 - weighted_acc: 0.7508 - val_loss: 0.9068 - val_weighted_acc: 0.6867\n",
      "\n",
      "Epoch 00029: val_weighted_acc did not improve from 0.68736\n",
      "Epoch 30/300\n",
      "173/173 [==============================] - 29s 168ms/step - loss: 0.7220 - weighted_acc: 0.7528 - val_loss: 0.9095 - val_weighted_acc: 0.6858\n",
      "\n",
      "Epoch 00030: val_weighted_acc did not improve from 0.68736\n",
      "Epoch 31/300\n",
      "173/173 [==============================] - 29s 168ms/step - loss: 0.7188 - weighted_acc: 0.7539 - val_loss: 0.9047 - val_weighted_acc: 0.6878\n",
      "\n",
      "Epoch 00031: val_weighted_acc improved from 0.68736 to 0.68779, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-31-0.754-0.688.hdf5\n",
      "Epoch 32/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.7165 - weighted_acc: 0.7544 - val_loss: 0.9082 - val_weighted_acc: 0.6860\n",
      "\n",
      "Epoch 00032: val_weighted_acc did not improve from 0.68779\n",
      "Epoch 33/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.7129 - weighted_acc: 0.7561 - val_loss: 0.9073 - val_weighted_acc: 0.6875\n",
      "\n",
      "Epoch 00033: val_weighted_acc did not improve from 0.68779\n",
      "Epoch 34/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.7108 - weighted_acc: 0.7566 - val_loss: 0.9037 - val_weighted_acc: 0.6884\n",
      "\n",
      "Epoch 00034: val_weighted_acc improved from 0.68779 to 0.68844, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-34-0.757-0.688.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.7072 - weighted_acc: 0.7578 - val_loss: 0.9038 - val_weighted_acc: 0.6887\n",
      "\n",
      "Epoch 00035: val_weighted_acc improved from 0.68844 to 0.68869, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-35-0.758-0.689.hdf5\n",
      "Epoch 36/300\n",
      "173/173 [==============================] - 29s 166ms/step - loss: 0.7035 - weighted_acc: 0.7595 - val_loss: 0.9115 - val_weighted_acc: 0.6855\n",
      "\n",
      "Epoch 00036: val_weighted_acc did not improve from 0.68869\n",
      "Epoch 37/300\n",
      "173/173 [==============================] - 29s 166ms/step - loss: 0.7006 - weighted_acc: 0.7603 - val_loss: 0.9019 - val_weighted_acc: 0.6900\n",
      "\n",
      "Epoch 00037: val_weighted_acc improved from 0.68869 to 0.68997, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-37-0.760-0.690.hdf5\n",
      "Epoch 38/300\n",
      "173/173 [==============================] - 29s 166ms/step - loss: 0.6979 - weighted_acc: 0.7614 - val_loss: 0.9125 - val_weighted_acc: 0.6878\n",
      "\n",
      "Epoch 00038: val_weighted_acc did not improve from 0.68997\n",
      "Epoch 39/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6951 - weighted_acc: 0.7622 - val_loss: 0.9041 - val_weighted_acc: 0.6896\n",
      "\n",
      "Epoch 00039: val_weighted_acc did not improve from 0.68997\n",
      "Epoch 40/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6915 - weighted_acc: 0.7637 - val_loss: 0.9105 - val_weighted_acc: 0.6880\n",
      "\n",
      "Epoch 00040: val_weighted_acc did not improve from 0.68997\n",
      "Epoch 41/300\n",
      "173/173 [==============================] - 29s 168ms/step - loss: 0.6895 - weighted_acc: 0.7644 - val_loss: 0.9012 - val_weighted_acc: 0.6909\n",
      "\n",
      "Epoch 00041: val_weighted_acc improved from 0.68997 to 0.69088, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-41-0.764-0.691.hdf5\n",
      "Epoch 42/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6866 - weighted_acc: 0.7656 - val_loss: 0.9120 - val_weighted_acc: 0.6865\n",
      "\n",
      "Epoch 00042: val_weighted_acc did not improve from 0.69088\n",
      "Epoch 43/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6840 - weighted_acc: 0.7669 - val_loss: 0.9106 - val_weighted_acc: 0.6891\n",
      "\n",
      "Epoch 00043: val_weighted_acc did not improve from 0.69088\n",
      "Epoch 44/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6805 - weighted_acc: 0.7678 - val_loss: 0.9101 - val_weighted_acc: 0.6874\n",
      "\n",
      "Epoch 00044: val_weighted_acc did not improve from 0.69088\n",
      "Epoch 45/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6772 - weighted_acc: 0.7692 - val_loss: 0.9087 - val_weighted_acc: 0.6887\n",
      "\n",
      "Epoch 00045: val_weighted_acc did not improve from 0.69088\n",
      "Epoch 46/300\n",
      "173/173 [==============================] - 29s 166ms/step - loss: 0.6748 - weighted_acc: 0.7700 - val_loss: 0.9081 - val_weighted_acc: 0.6885\n",
      "\n",
      "Epoch 00046: val_weighted_acc did not improve from 0.69088\n",
      "Epoch 47/300\n",
      "173/173 [==============================] - 29s 165ms/step - loss: 0.6723 - weighted_acc: 0.7705 - val_loss: 0.9113 - val_weighted_acc: 0.6887\n",
      "\n",
      "Epoch 00047: val_weighted_acc did not improve from 0.69088\n",
      "Epoch 48/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6683 - weighted_acc: 0.7724 - val_loss: 0.9108 - val_weighted_acc: 0.6881\n",
      "\n",
      "Epoch 00048: val_weighted_acc did not improve from 0.69088\n",
      "Epoch 49/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6658 - weighted_acc: 0.7733 - val_loss: 0.9061 - val_weighted_acc: 0.6907\n",
      "\n",
      "Epoch 00049: val_weighted_acc did not improve from 0.69088\n",
      "Epoch 50/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6628 - weighted_acc: 0.7741 - val_loss: 0.9094 - val_weighted_acc: 0.6898\n",
      "\n",
      "Epoch 00050: val_weighted_acc did not improve from 0.69088\n",
      "Epoch 51/300\n",
      "173/173 [==============================] - 29s 168ms/step - loss: 0.6599 - weighted_acc: 0.7750 - val_loss: 0.9097 - val_weighted_acc: 0.6911\n",
      "\n",
      "Epoch 00051: val_weighted_acc improved from 0.69088 to 0.69112, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-51-0.775-0.691.hdf5\n",
      "Epoch 52/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6568 - weighted_acc: 0.7769 - val_loss: 0.9117 - val_weighted_acc: 0.6899\n",
      "\n",
      "Epoch 00052: val_weighted_acc did not improve from 0.69112\n",
      "Epoch 53/300\n",
      "173/173 [==============================] - 29s 168ms/step - loss: 0.6546 - weighted_acc: 0.7769 - val_loss: 0.9114 - val_weighted_acc: 0.6910\n",
      "\n",
      "Epoch 00053: val_weighted_acc did not improve from 0.69112\n",
      "Epoch 54/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6515 - weighted_acc: 0.7787 - val_loss: 0.9130 - val_weighted_acc: 0.6898\n",
      "\n",
      "Epoch 00054: val_weighted_acc did not improve from 0.69112\n",
      "Epoch 55/300\n",
      "173/173 [==============================] - 29s 168ms/step - loss: 0.6496 - weighted_acc: 0.7797 - val_loss: 0.9118 - val_weighted_acc: 0.6908\n",
      "\n",
      "Epoch 00055: val_weighted_acc did not improve from 0.69112\n",
      "Epoch 56/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6461 - weighted_acc: 0.7807 - val_loss: 0.9086 - val_weighted_acc: 0.6922\n",
      "\n",
      "Epoch 00056: val_weighted_acc improved from 0.69112 to 0.69222, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-56-0.781-0.692.hdf5\n",
      "Epoch 57/300\n",
      "173/173 [==============================] - 29s 166ms/step - loss: 0.6443 - weighted_acc: 0.7811 - val_loss: 0.9186 - val_weighted_acc: 0.6869\n",
      "\n",
      "Epoch 00057: val_weighted_acc did not improve from 0.69222\n",
      "Epoch 58/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6408 - weighted_acc: 0.7822 - val_loss: 0.9107 - val_weighted_acc: 0.6891\n",
      "\n",
      "Epoch 00058: val_weighted_acc did not improve from 0.69222\n",
      "Epoch 59/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6384 - weighted_acc: 0.7835 - val_loss: 0.9130 - val_weighted_acc: 0.6894\n",
      "\n",
      "Epoch 00059: val_weighted_acc did not improve from 0.69222\n",
      "Epoch 60/300\n",
      "173/173 [==============================] - 29s 166ms/step - loss: 0.6363 - weighted_acc: 0.7843 - val_loss: 0.9095 - val_weighted_acc: 0.6926\n",
      "\n",
      "Epoch 00060: val_weighted_acc improved from 0.69222 to 0.69262, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-60-0.784-0.693.hdf5\n",
      "Epoch 61/300\n",
      "173/173 [==============================] - 29s 166ms/step - loss: 0.6339 - weighted_acc: 0.7852 - val_loss: 0.9169 - val_weighted_acc: 0.6899\n",
      "\n",
      "Epoch 00061: val_weighted_acc did not improve from 0.69262\n",
      "Epoch 62/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6301 - weighted_acc: 0.7860 - val_loss: 0.9117 - val_weighted_acc: 0.6913\n",
      "\n",
      "Epoch 00062: val_weighted_acc did not improve from 0.69262\n",
      "Epoch 63/300\n",
      "173/173 [==============================] - 29s 166ms/step - loss: 0.6277 - weighted_acc: 0.7873 - val_loss: 0.9162 - val_weighted_acc: 0.6899\n",
      "\n",
      "Epoch 00063: val_weighted_acc did not improve from 0.69262\n",
      "Epoch 64/300\n",
      "173/173 [==============================] - 29s 166ms/step - loss: 0.6259 - weighted_acc: 0.7879 - val_loss: 0.9115 - val_weighted_acc: 0.6925\n",
      "\n",
      "Epoch 00064: val_weighted_acc did not improve from 0.69262\n",
      "Epoch 65/300\n",
      "173/173 [==============================] - 29s 165ms/step - loss: 0.6243 - weighted_acc: 0.7890 - val_loss: 0.9145 - val_weighted_acc: 0.6915\n",
      "\n",
      "Epoch 00065: val_weighted_acc did not improve from 0.69262\n",
      "Epoch 66/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6209 - weighted_acc: 0.7901 - val_loss: 0.9084 - val_weighted_acc: 0.6934\n",
      "\n",
      "Epoch 00066: val_weighted_acc improved from 0.69262 to 0.69336, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-66-0.790-0.693.hdf5\n",
      "Epoch 67/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6189 - weighted_acc: 0.7905 - val_loss: 0.9143 - val_weighted_acc: 0.6925\n",
      "\n",
      "Epoch 00067: val_weighted_acc did not improve from 0.69336\n",
      "Epoch 68/300\n",
      "173/173 [==============================] - 29s 166ms/step - loss: 0.6160 - weighted_acc: 0.7918 - val_loss: 0.9125 - val_weighted_acc: 0.6930\n",
      "\n",
      "Epoch 00068: val_weighted_acc did not improve from 0.69336\n",
      "Epoch 69/300\n",
      "173/173 [==============================] - 29s 166ms/step - loss: 0.6135 - weighted_acc: 0.7926 - val_loss: 0.9168 - val_weighted_acc: 0.6926\n",
      "\n",
      "Epoch 00069: val_weighted_acc did not improve from 0.69336\n",
      "Epoch 70/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6123 - weighted_acc: 0.7932 - val_loss: 0.9181 - val_weighted_acc: 0.6909\n",
      "\n",
      "Epoch 00070: val_weighted_acc did not improve from 0.69336\n",
      "Epoch 71/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6097 - weighted_acc: 0.7938 - val_loss: 0.9167 - val_weighted_acc: 0.6941\n",
      "\n",
      "Epoch 00071: val_weighted_acc improved from 0.69336 to 0.69407, saving model to baseline_modifications/residual2_model#onehot#sequence_profile@conv3_5_7_11_21@dense_1000@lstm1000@droplstm0.5@filtersize_32/weights-improvement-71-0.794-0.694.hdf5\n",
      "Epoch 72/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6067 - weighted_acc: 0.7948 - val_loss: 0.9157 - val_weighted_acc: 0.6932\n",
      "\n",
      "Epoch 00072: val_weighted_acc did not improve from 0.69407\n",
      "Epoch 73/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6039 - weighted_acc: 0.7960 - val_loss: 0.9170 - val_weighted_acc: 0.6937\n",
      "\n",
      "Epoch 00073: val_weighted_acc did not improve from 0.69407\n",
      "Epoch 74/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.6023 - weighted_acc: 0.7966 - val_loss: 0.9166 - val_weighted_acc: 0.6922\n",
      "\n",
      "Epoch 00074: val_weighted_acc did not improve from 0.69407\n",
      "Epoch 75/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.5992 - weighted_acc: 0.7975 - val_loss: 0.9152 - val_weighted_acc: 0.6928\n",
      "\n",
      "Epoch 00075: val_weighted_acc did not improve from 0.69407\n",
      "Epoch 76/300\n",
      "173/173 [==============================] - 29s 166ms/step - loss: 0.5977 - weighted_acc: 0.7986 - val_loss: 0.9188 - val_weighted_acc: 0.6919\n",
      "\n",
      "Epoch 00076: val_weighted_acc did not improve from 0.69407\n",
      "Epoch 77/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.5945 - weighted_acc: 0.7998 - val_loss: 0.9170 - val_weighted_acc: 0.6916\n",
      "\n",
      "Epoch 00077: val_weighted_acc did not improve from 0.69407\n",
      "Epoch 78/300\n",
      "173/173 [==============================] - 29s 165ms/step - loss: 0.5927 - weighted_acc: 0.8003 - val_loss: 0.9197 - val_weighted_acc: 0.6923\n",
      "\n",
      "Epoch 00078: val_weighted_acc did not improve from 0.69407\n",
      "Epoch 79/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.5901 - weighted_acc: 0.8012 - val_loss: 0.9202 - val_weighted_acc: 0.6928\n",
      "\n",
      "Epoch 00079: val_weighted_acc did not improve from 0.69407\n",
      "Epoch 80/300\n",
      "173/173 [==============================] - 29s 168ms/step - loss: 0.5894 - weighted_acc: 0.8009 - val_loss: 0.9209 - val_weighted_acc: 0.6935\n",
      "\n",
      "Epoch 00080: val_weighted_acc did not improve from 0.69407\n",
      "Epoch 81/300\n",
      "173/173 [==============================] - 29s 167ms/step - loss: 0.5871 - weighted_acc: 0.8023 - val_loss: 0.9247 - val_weighted_acc: 0.6912\n",
      "\n",
      "Epoch 00081: val_weighted_acc did not improve from 0.69407\n"
     ]
    }
   ],
   "source": [
    "run_baseline(epochs=300, setting_name='residual2_', gpu='0', train_batch_size=32,\n",
    "                 test_batch_size=100, patience=10, features_to_use=['onehot', 'sequence_profile'], convs=[3,5,7,11,21], dense_size=1000, lstm_size=1000,use_CRF=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
